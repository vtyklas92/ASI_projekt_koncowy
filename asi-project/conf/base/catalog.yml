#================================================================================
# Pipeline: data_engineering
#================================================================================

# Wejście: Ścieżka do surowych danych nie jest zarządzana przez Kedro,
# ale podajemy ją w parametrach.

# Wyjście: Podzielone zbiory danych, które będą wersjonowane.
train_data:
  type: pandas.CSVDataSet
  filepath: data/02_intermediate/train_data.csv


test_data:
  type: pandas.CSVDataSet
  filepath: data/02_intermediate/test_data.csv


#================================================================================
# Pipeline: data_science
#================================================================================

# Wyjścia: Wytrenowany model, raport i wykres - wszystko wersjonowane.
autogluon_predictor:
  type: pickle.PickleDataSet
  filepath: data/06_models/autogluon_pokemon_predictor.pkl
  versioned: true
  # Uwaga: AutoGluon zapisuje całe foldery. PickleDataSet może być niewystarczający
  # dla bardzo dużych modeli lub jeśli chcesz przenosić model. W takim scenariuszu
  # lepsze byłoby stworzenie własnego DataSet'u lub zarządzanie ścieżką.
  # Na potrzeby tego przykładu, pickle jest najprostszym rozwiązaniem.

classification_report:
  type: json.JSONDataSet
  filepath: data/07_model_output/classification_report.json
  versioned: true

confusion_matrix_plot:
  type: matplotlib.MatplotlibWriter
  filepath: data/08_reporting/confusion_matrix.png
  versioned: true